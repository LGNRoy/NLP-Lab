{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK_wn note.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LGNRoy/NLP-Lab/blob/master/NLTK_wn_note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7g3eNemEOklg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NLTK Library and WordNet"
      ]
    },
    {
      "metadata": {
        "id": "D8btJKEBxSS1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept."
      ]
    },
    {
      "metadata": {
        "id": "ofWRw7omOeWf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In Python, NLTK library includes English WordNet.\n",
        "\n",
        "**To use wordnet, you need to download the wordnet data via NLTK library**\n",
        "\n",
        " * **[NLTK](https://www.nltk.org/)** is a **N**atural **L**anguage **T**ool**k**iit for python. "
      ]
    },
    {
      "metadata": {
        "id": "iVqxuaIpOIOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2cusD7IovCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## WordNet"
      ]
    },
    {
      "metadata": {
        "id": "OuDwzN6OosjB",
        "colab_type": "code",
        "outputId": "ef51fbac-1330-4e7c-f7cc-3e83ce5b3a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "1JKvb0XKNzxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucVb1XeAnnFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's get a set of synonyms that share a common meaning."
      ]
    },
    {
      "metadata": {
        "id": "ecoLLQPlxlOc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dog = wn.synset('dog.n.01')\n",
        "person = wn.synset('person.n.01')\n",
        "cat = wn.synset('cat.n.01')\n",
        "computer = wn.synset('computer.n.01')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4rd7JPrr4sc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### path_similarity()\n",
        "path_similarity() returns a score denoting how similar two word senses are, based on the shortest path that connects the senses in the is-a (hypernym/hypnoym) taxonomy. The score is in the range 0 to 1."
      ]
    },
    {
      "metadata": {
        "id": "aiTFSsHqsREt",
        "colab_type": "code",
        "outputId": "74bc37f3-1540-40c6-f507-d2bc0797b76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"dog<->cat : \", wn.path_similarity(dog,cat))\n",
        "print(\"person<->cat : \", wn.path_similarity(person,cat))\n",
        "print(\"person<->dog : \", wn.path_similarity(person,dog))\n",
        "print(\"person<->computer : \", wn.path_similarity(person,computer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog<->cat :  0.2\n",
            "person<->cat :  0.1\n",
            "person<->dog :  0.2\n",
            "person<->computer :  0.1111111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rJfYbAtPrMNS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wu-Palmer Similarity (wup_similarity() )\n",
        "wup_similarity() returns a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node)."
      ]
    },
    {
      "metadata": {
        "id": "Jno6d9Mdrbu0",
        "colab_type": "code",
        "outputId": "336cc0b4-4f1f-4b78-c0af-4c0e2295c952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"dog<->cat : \", wn.wup_similarity(dog,cat))\n",
        "print(\"person<->cat : \", wn.wup_similarity(person,cat))\n",
        "print(\"person<->dog : \", wn.wup_similarity(person,dog))\n",
        "print(\"person<->computer : \", wn.wup_similarity(person,computer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog<->cat :  0.8571428571428571\n",
            "person<->cat :  0.5714285714285714\n",
            "person<->dog :  0.75\n",
            "person<->computer :  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RVtVC7LnqS9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise\n",
        "\n",
        "Write a program to find the most and the least similar words by nesting its synonyms or antonyms. To compare words, you can use two similarity measurement functions (path_similarity() and wup_similarity()). Please give a nesting limit so that your program cannot nest more than 6 times (as argument and should have default value). \n",
        "\n",
        "Useful information: [NLTK-WordNet](http://www.nltk.org/howto/wordnet.html#synsets)\n",
        "\n",
        "Note. Some words do not have antonyms (dog, cat, person, computer, etc.)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "v2jM0mZT7Kbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_similar_synset(synset, max_nesting=6):\n",
        "  similar_synsets = {\n",
        "      \"least\":\"\",\n",
        "      \"most\":\"\"\n",
        "  }\n",
        "  \n",
        "  # we suppose the word is synset\n",
        "  def itereator(synset, max_nesting, wordbag):\n",
        "    synonyms = []\n",
        "    antonyms = []\n",
        "\n",
        "    for lemma in synset.lemmas():\n",
        "      meaning = lemma.name()\n",
        "      synonyms += wn.synsets(meaning)\n",
        "\n",
        "      ants = lemma.antonyms()\n",
        "      if ants:\n",
        "        for ant in ants:\n",
        "          antonyms.append(ant.synset())\n",
        "\n",
        "    synonyms = list(set(synonyms))\n",
        "    antonyms = list(set(antonyms))\n",
        "\n",
        "    if max_nesting > 0:\n",
        "      max_nesting -= 1\n",
        "      for syn in synonyms:\n",
        "        if syn not in wordbag:\n",
        "  #         print(\"{}\\t syn: {}\".format(max_nesting, syn))\n",
        "          wordbag.append(syn)\n",
        "          itereator(synset, max_nesting, wordbag)\n",
        "\n",
        "      for ant in antonyms:\n",
        "        if ant not in wordbag:\n",
        "  #         print(\"{}\\t ant: {}\".format(max_nesting, ant))\n",
        "          wordbag.append(ant)\n",
        "          itereator(synset, max_nesting, wordbag)\n",
        "   \n",
        "  wordbag = []\n",
        "  itereator(synset, max_nesting, wordbag)\n",
        "#   print(wordbag)\n",
        "#   print(len(wordbag))\n",
        "  wordbag.remove(synset)\n",
        "  \n",
        "  least, most= 1, 0\n",
        "  for item in wordbag:\n",
        "    simi = wn.wup_similarity(item,word)\n",
        "    if simi:\n",
        "      if simi < least:\n",
        "        least = simi\n",
        "        similar_synsets[\"least\"] = item.name()\n",
        "\n",
        "      if simi > most:\n",
        "        most = simi\n",
        "        similar_synsets[\"most\"] = item.name()\n",
        "\n",
        "      \n",
        "      \n",
        "  return similar_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrA3rdzGp1gk",
        "colab_type": "code",
        "outputId": "692027cc-74f2-4f58-df30-841319c6e7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "word = wn.synset('give.v.01')\n",
        "print(word.definition())\n",
        "print(word.examples()[0])\n",
        "print(find_similar_synset(word, max_nesting=6))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cause to have, in the abstract sense or physical sense\n",
            "She gave him a black eye\n",
            "{'least': 'respect.v.01', 'most': 'value.n.06'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CrYcJ_3v7bzC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# You should submit \"ipynb\" file (You can download it from \"File\" > \"Download .ipynb\") to Canvas\n",
        "# You can write extra functions\n",
        "\n",
        "def find_similar_words(word, max_nesting=6):\n",
        "  similar_words = {\n",
        "      \"least\":\"\",\n",
        "      \"most\":\"\"\n",
        "  }\n",
        "  \n",
        "  # we proposed word is str\n",
        "  def itereator(word, max_nesting, wordbag):\n",
        "    synonyms = []\n",
        "    antonyms = []\n",
        "    \n",
        "    for syn in wn.synsets(word):\n",
        "      for lemma in syn.lemmas():\n",
        "        synonyms.append(lemma.name())\n",
        "        for ant in lemma.antonyms():\n",
        "          antonyms.append(ant.name())\n",
        "\n",
        "    synonyms = list(set(synonyms))\n",
        "    antonyms = list(set(antonyms))\n",
        "\n",
        "    if max_nesting > 0:\n",
        "      max_nesting -= 1\n",
        "      for syn in synonyms:\n",
        "        if syn not in wordbag:\n",
        "          wordbag.append(syn)\n",
        "          itereator(word, max_nesting, wordbag)\n",
        "\n",
        "      for ant in antonyms:\n",
        "        if ant not in wordbag:\n",
        "          wordbag.append(ant)\n",
        "          itereator(word, max_nesting, wordbag)\n",
        "   \n",
        "  wordbag = []\n",
        "  itereator(word, max_nesting, wordbag)\n",
        "  if word in wordbag:\n",
        "    wordbag.remove(word)\n",
        "  \n",
        "  least, most= 1, 0\n",
        "  word_syns = wn.synsets(word)\n",
        "  for item in wordbag:\n",
        "    sum_simi = 0\n",
        "    count = 0\n",
        "    for word_syn in word_syns:\n",
        "      for item_syn in wn.synsets(item):\n",
        "        simi = wn.wup_similarity(item_syn,word_syn)\n",
        "        if simi: \n",
        "          count += 1\n",
        "          sum_simi += simi\n",
        "    \n",
        "    if count > 0:\n",
        "      simi = sum_simi/count\n",
        "      if simi:\n",
        "        if simi < least:\n",
        "          least = simi\n",
        "          similar_words[\"least\"] = item\n",
        "\n",
        "        if simi > most:\n",
        "          most = simi\n",
        "          similar_words[\"most\"] = item\n",
        "      \n",
        "  return similar_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ls1xtI5X_SXd",
        "colab_type": "code",
        "outputId": "9e05e149-f2d3-4271-f25d-987055570a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "find_similar_words('dog', max_nesting=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'least': 'frank', 'most': 'domestic_dog'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "XpVhKZvgxBm9",
        "colab_type": "code",
        "outputId": "4d617aae-b817-4cd0-a75e-2a2937ed3884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#词性不同时，相似怎么处理，\n",
        "#是不是应该过滤，保持词性一致？\n",
        "a = wn.synset('good.s.20')\n",
        "b = wn.synset('good.n.02')\n",
        "print(wn.wup_similarity(dog,cat))\n",
        "print(wn.path_similarity(dog,cat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KJiL8VV7SSFI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  # 假设输入的word是str\n",
        "  def itereator(word, nax_nesting, wordbag):\n",
        "    synonyms = []\n",
        "    antonyms = []\n",
        "    \n",
        "    \n",
        "    ## 获取这个词所有的意思\n",
        "    ## 每个意思找近义词和反义词\n",
        "    \n",
        "    for syn in wn.synsets(word):\n",
        "      print(\"syn:\",syn)\n",
        "      for lemma in syn.lemmas():\n",
        "        print(\"lemma:\",lemma.name())\n",
        "        synonyms.append(lemma.name())\n",
        "        \n",
        "        ant = lemma.antonyms()\n",
        "        if ant:\n",
        "          antonyms.append(ant[0].name())\n",
        "    \n",
        "    synonyms = list(set(synonyms))\n",
        "    print(synonyms)\n",
        "    antonyms = list(set(antonyms))\n",
        "    print(antonyms)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vp7k5gD6iE7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "目前的问题是 lemmas()代表的是什么意思"
      ]
    },
    {
      "metadata": {
        "id": "sYuzGJSGhlSs",
        "colab_type": "code",
        "outputId": "38be5a87-cb66-44cc-d250-c6bf279d470b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "# 假设输入的word是synset\n",
        "def itereator(word, max_nesting, wordbag):\n",
        "  synonyms = []\n",
        "  antonyms = []\n",
        "\n",
        "  for lemma in word.lemmas():\n",
        "    meaning = lemma.name()\n",
        "    synonyms += wn.synsets(meaning)\n",
        "\n",
        "    ants = lemma.antonyms()\n",
        "    if ants:\n",
        "      for ant in ants:\n",
        "        antonyms.append(ant.synset())\n",
        "\n",
        "  synonyms = list(set(synonyms))\n",
        "  antonyms = list(set(antonyms))\n",
        "  \n",
        "  #可能要改成BFS\n",
        "  \n",
        "  #DFS \n",
        "  if (max_nesting > 0):\n",
        "    max_nesting -= 1\n",
        "#     print(max_nesting > 0)\n",
        "#     print(synonyms)\n",
        "    for syn in synonyms:\n",
        "#       print(max_nesting)\n",
        "      if syn not in wordbag:\n",
        "        print(\"{}\\t syn: {}\".format(max_nesting, syn))\n",
        "        wordbag.append(syn)\n",
        "        itereator(word, max_nesting, wordbag)\n",
        "\n",
        "    for ant in antonyms:\n",
        "      if ant not in wordbag:\n",
        "        print(\"{}\\t ant: {}\".format(max_nesting, ant))\n",
        "        wordbag.append(ant)\n",
        "        itereator(word, max_nesting, wordbag)\n",
        "\n",
        "wordbag = []\n",
        "itereator(wn.synset('car.n.01'),6,wordbag)\n",
        "print(wordbag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\t syn: Synset('car.n.04')\n",
            "4\t syn: Synset('machine.v.02')\n",
            "3\t syn: Synset('car.n.03')\n",
            "2\t syn: Synset('cable_car.n.01')\n",
            "1\t syn: Synset('machine.n.01')\n",
            "0\t syn: Synset('machine.n.05')\n",
            "0\t syn: Synset('machine.n.03')\n",
            "0\t syn: Synset('car.n.02')\n",
            "0\t syn: Synset('machine.n.04')\n",
            "0\t syn: Synset('car.n.01')\n",
            "0\t syn: Synset('machine.v.01')\n",
            "0\t syn: Synset('automobile.v.01')\n",
            "0\t syn: Synset('machine.n.02')\n",
            "[Synset('car.n.04'), Synset('machine.v.02'), Synset('car.n.03'), Synset('cable_car.n.01'), Synset('machine.n.01'), Synset('machine.n.05'), Synset('machine.n.03'), Synset('car.n.02'), Synset('machine.n.04'), Synset('car.n.01'), Synset('machine.v.01'), Synset('automobile.v.01'), Synset('machine.n.02')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jpm9-SrYabiQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*   从下面的例子可以看出， synsets的输出是包含了输入的这个词的所有单词\n",
        "*   每个单词再根据意思求出所有的近义词\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "hbYUfg4sZpcO",
        "colab_type": "code",
        "outputId": "26ac16af-38fd-4715-ec09-31c6138e2b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "# 假设，synsets求出来的是所有的近义词\n",
        "def itereator(word, nax_nesting, wordbag):\n",
        "  synonyms = []\n",
        "  antonyms = []\n",
        "\n",
        "\n",
        "  ## 获取这个词所有的意思\n",
        "  ## 每个意思找近义词和反义词\n",
        "\n",
        "  for syn in wn.synsets(word):\n",
        "    print(\"     syn:\",syn)\n",
        "    for lemma in syn.lemmas():\n",
        "      print(\"lemma:\",lemma)\n",
        "      synonyms.append(lemma.name())\n",
        "  synonyms = list(set(synonyms))\n",
        "  print(synonyms)\n",
        "    \n",
        "itereator('car',1,[])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     syn: Synset('car.n.01')\n",
            "lemma: Lemma('car.n.01.car')\n",
            "lemma: Lemma('car.n.01.auto')\n",
            "lemma: Lemma('car.n.01.automobile')\n",
            "lemma: Lemma('car.n.01.machine')\n",
            "lemma: Lemma('car.n.01.motorcar')\n",
            "     syn: Synset('car.n.02')\n",
            "lemma: Lemma('car.n.02.car')\n",
            "lemma: Lemma('car.n.02.railcar')\n",
            "lemma: Lemma('car.n.02.railway_car')\n",
            "lemma: Lemma('car.n.02.railroad_car')\n",
            "     syn: Synset('car.n.03')\n",
            "lemma: Lemma('car.n.03.car')\n",
            "lemma: Lemma('car.n.03.gondola')\n",
            "     syn: Synset('car.n.04')\n",
            "lemma: Lemma('car.n.04.car')\n",
            "lemma: Lemma('car.n.04.elevator_car')\n",
            "     syn: Synset('cable_car.n.01')\n",
            "lemma: Lemma('cable_car.n.01.cable_car')\n",
            "lemma: Lemma('cable_car.n.01.car')\n",
            "['railway_car', 'car', 'motorcar', 'gondola', 'railcar', 'railroad_car', 'elevator_car', 'machine', 'auto', 'cable_car', 'automobile']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "30kFdMAbBnWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extension\n",
        "Test your program with 10 different words (selects randomly by yourself) and find the reasonable threshold limit for the number of nestings (by changing value for max_nesting argument)"
      ]
    },
    {
      "metadata": {
        "id": "iq6yaGo8CI_7",
        "colab_type": "code",
        "outputId": "c079ba4d-844a-4fd6-b15e-bb560659b04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "# This is an extension task. You do not need to submit this task for your assessment.\n",
        "\n",
        "\n",
        "words = [\"test\", \"program\", \"ten\", \"different\", \"word\", \"assessment\", \"limit\", \"number\", \"nesting\", \"value\"]\n",
        "print(\"The length of word list is:\", len(words))\n",
        "\n",
        "max_nesting = 100\n",
        "print(\"The max nesting is:\", max_nesting)\n",
        "\n",
        "table = []\n",
        "\n",
        "for word in words:\n",
        "#   word_syn = wn.synsets(word)[0]\n",
        "#   similar_words = find_similar_words(word_syn, max_nesting)\n",
        "#   table.append([word_syn.name(), similar_words[\"least\"], similar_words[\"most\"]])\n",
        "\n",
        "  similar_words = find_similar_words(word, max_nesting)\n",
        "  table.append([word, similar_words[\"least\"], similar_words[\"most\"]])\n",
        "  \n",
        "#   print(word+\"\\t\\t\", find_similar_words(word_syn, max_nesting))\n",
        "\n",
        "import pandas as pd\n",
        "table = pd.DataFrame(table)\n",
        "table.columns = ['word','least','most']\n",
        "table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of word list is: 10\n",
            "The max nesting is: 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>least</th>\n",
              "      <th>most</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>prove</td>\n",
              "      <td>psychometric_test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>program</td>\n",
              "      <td>platform</td>\n",
              "      <td>syllabus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ten</td>\n",
              "      <td>tenner</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>different</td>\n",
              "      <td>like</td>\n",
              "      <td>dissimilar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word</td>\n",
              "      <td>formulate</td>\n",
              "      <td>word_of_honor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>assessment</td>\n",
              "      <td>judgement</td>\n",
              "      <td>appraisal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>limit</td>\n",
              "      <td>specify</td>\n",
              "      <td>limit_point</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>number</td>\n",
              "      <td>numerate</td>\n",
              "      <td>phone_number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>nesting</td>\n",
              "      <td>nuzzle</td>\n",
              "      <td>nest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>value</td>\n",
              "      <td>assess</td>\n",
              "      <td>economic_value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         word      least               most\n",
              "0        test      prove  psychometric_test\n",
              "1     program   platform           syllabus\n",
              "2         ten     tenner                 10\n",
              "3   different       like         dissimilar\n",
              "4        word  formulate      word_of_honor\n",
              "5  assessment  judgement          appraisal\n",
              "6       limit    specify        limit_point\n",
              "7      number   numerate       phone_number\n",
              "8     nesting     nuzzle               nest\n",
              "9       value     assess     economic_value"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "W2tQYl2z4CA9",
        "colab_type": "code",
        "outputId": "1ef6f6c7-63a5-49df-a863-441679215e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "# 问题单词：different limit\n",
        "\n",
        "word = 'different'\n",
        "item = 'dissimilar'\n",
        "\n",
        "sum_simi = 0\n",
        "count = 0\n",
        "for word_syn in wn.synsets(word):\n",
        "  for item_syn in wn.synsets(item):\n",
        "    count += 1\n",
        "    simi = wn.wup_similarity(item_syn,word_syn)\n",
        "    print(count, '\\t',word_syn, '\\t',item_syn, '\\t',simi)\n",
        "    if simi: \n",
        "      sum_simi += simi\n",
        "\n",
        "simi = sum_simi/count\n",
        "print(simi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 \t Synset('different.a.01') \t Synset('dissimilar.a.01') \t None\n",
            "2 \t Synset('different.a.01') \t Synset('unalike.a.01') \t None\n",
            "3 \t Synset('different.a.01') \t Synset('unlike.a.01') \t None\n",
            "4 \t Synset('different.s.02') \t Synset('dissimilar.a.01') \t None\n",
            "5 \t Synset('different.s.02') \t Synset('unalike.a.01') \t None\n",
            "6 \t Synset('different.s.02') \t Synset('unlike.a.01') \t None\n",
            "7 \t Synset('different.s.03') \t Synset('dissimilar.a.01') \t None\n",
            "8 \t Synset('different.s.03') \t Synset('unalike.a.01') \t None\n",
            "9 \t Synset('different.s.03') \t Synset('unlike.a.01') \t None\n",
            "10 \t Synset('unlike.a.01') \t Synset('dissimilar.a.01') \t None\n",
            "11 \t Synset('unlike.a.01') \t Synset('unalike.a.01') \t None\n",
            "12 \t Synset('unlike.a.01') \t Synset('unlike.a.01') \t 1.0\n",
            "13 \t Synset('different.s.05') \t Synset('dissimilar.a.01') \t None\n",
            "14 \t Synset('different.s.05') \t Synset('unalike.a.01') \t None\n",
            "15 \t Synset('different.s.05') \t Synset('unlike.a.01') \t None\n",
            "0.06666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQXyrjw6PLRU",
        "colab_type": "code",
        "outputId": "5d2c33ad-44b9-469a-f4ca-3e03454f8eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "# 查找指定词汇的同义词\n",
        "print(wn.synsets('motorcar'))\n",
        "print(wn.synset('car.n.01').lemma_names)\n",
        "motorcar = wn.synset('car.n.01')\n",
        "types_of_motorcar = motorcar.hyponyms()\n",
        "print(types_of_motorcar[26])\n",
        "#  'method' object is not iterable\n",
        "# print([lemma.name for synset in types_of_motorcar for lemma in synset.lemmas])\n",
        "\n",
        "# 反义词\n",
        "wn.lemma('supply.n.02.supply').antonyms()[0].name\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Synset('car.n.01')]\n",
            "<bound method Synset.lemma_names of Synset('car.n.01')>\n",
            "Synset('stanley_steamer.n.01')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Lemma.name of Lemma('demand.n.02.demand')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}